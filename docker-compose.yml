name: youtube-data-pipeline

services:
  # FastAPI Backend (local MySQL)
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - DB_HOST=host.docker.internal
      - DB_PORT=3307
      - DB_USER=${DB_USER}
      - DB_PASSWORD=${DB_PASSWORD}
      - DB_NAME=${DB_NAME}
      - ML_API_BASE_URL=http://ml-api:8100
    env_file:
      - .env
    volumes:
      - ./backend:/app
    depends_on:
      - ml-api
    restart: unless-stopped
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

  # Lightweight Web API (search/trends/cache)
  web-api:
    build:
      context: ./web-api
    container_name: web-api
    ports:
      - "8001:8000"
    environment:
      - REDIS_URL=redis://redis:6379/0
      - ML_API_BASE_URL=http://ml-api:8100
    depends_on:
      - redis
    restart: unless-stopped

  # ML Inference API (embeddings/sentiment/rerank)
  ml-api:
    build:
      context: ./ml-api
    container_name: ml-api
    ports:
      - "8100:8100"
    volumes:
      - ./backend/models/embeddings/m3_korean:/app/model/embeddings/m3_korean
      - ./backend/models/profanity/kcelectra:/app/model/profanity/kcelectra
      - ./backend/models/sentiment/koelectra:/app/model/sentiment/koelectra
    environment:
      - MODEL_PATH=/app/model/embeddings/m3_korean/model.onnx
    restart: unless-stopped

  # Redis cache
  redis:
    image: redis:7-alpine
    container_name: redis
    ports:
      - "6379:6379"
    restart: unless-stopped

  # React Frontend
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.dev
    ports:
      - "5173:5173"
    environment:
      - NODE_ENV=development
    volumes:
      - ./frontend:/app
      - /app/node_modules
    depends_on:
      - backend
    restart: unless-stopped
    stdin_open: true
    tty: true
    networks:
      - default
